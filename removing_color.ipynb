{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('images/5725_HASAN_MARAE Optic nerve.png_ right.png')\n",
    "\n",
    "# Define the color you want to remove (in BGR format)\n",
    "color_to_remove = np.array([ 45 , 33 ,143])  # For example, remove red color (in BGR format)\n",
    "\n",
    "# Define the tolerance for color matching (you can adjust this value)\n",
    "tolerance = 50\n",
    "\n",
    "# Create lower and upper bounds for color matching\n",
    "lower_bound = color_to_remove - tolerance\n",
    "upper_bound = color_to_remove + tolerance\n",
    "\n",
    "# Mask the image to identify pixels within the specified color range\n",
    "mask = cv2.inRange(image, lower_bound, upper_bound)\n",
    "\n",
    "# Invert the mask to keep the pixels outside the specified color range\n",
    "inverse_mask = cv2.bitwise_not(mask)\n",
    "\n",
    "# Apply the mask to remove the specified color from the image\n",
    "result = cv2.bitwise_and(image, image, mask=inverse_mask)\n",
    "\n",
    "# Display the original and resulting images\n",
    "cv2.imshow('Original Image', image)\n",
    "cv2.imshow('Result Image', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('images/5725_HASAN_MARAE Optic nerve.png_ right.png')\n",
    "\n",
    "# Define the color you want to remove (in BGR format)\n",
    "color_to_remove = np.array([ 32 ,220 , 22])  # For example, remove red color (in BGR format)\n",
    "\n",
    "# Define the tolerance for color matching (you can adjust this value)\n",
    "tolerance = 50\n",
    "\n",
    "# Create lower and upper bounds for color matching\n",
    "lower_bound = color_to_remove - tolerance\n",
    "upper_bound = color_to_remove + tolerance\n",
    "\n",
    "# Iterate through the image and replace each removed pixel with its neighbor\n",
    "for y in range(image.shape[0]):\n",
    "    for x in range(image.shape[1]):\n",
    "        # Check if the pixel color is within the specified color range\n",
    "        if (lower_bound <= image[y, x]).all() and (image[y, x] <= upper_bound).all():\n",
    "            # Replace the pixel color with the color of the neighboring pixel\n",
    "            if y > 0 and x > 0:\n",
    "                image[y, x] = image[y-1, x-1]\n",
    "            elif y > 0:\n",
    "                image[y, x] = image[y-1, x]\n",
    "            elif x > 0:\n",
    "                image[y, x] = image[y, x-1]\n",
    "\n",
    "# Display the resulting image\n",
    "cv2.imshow('Result Image', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def select_roi(image):\n",
    "    # Display the image and allow the user to select a ROI\n",
    "    roi = cv2.selectROI(\"Select ROI\", image, fromCenter=False, showCrosshair=False)\n",
    "    cv2.destroyAllWindows()\n",
    "    return roi\n",
    "\n",
    "def get_dominant_color(image, roi):\n",
    "    # Extract the selected ROI from the image\n",
    "    x, y, w, h = roi\n",
    "    selected_area = image[y:y+h, x:x+w]\n",
    "\n",
    "    # Flatten the selected area to a list of pixels\n",
    "    pixels = selected_area.reshape(-1, 3)\n",
    "\n",
    "    # Calculate the histogram of RGB values\n",
    "    hist = cv2.calcHist([pixels], [0, 1, 2], None, [256, 256, 256], [0, 256, 0, 256, 0, 256])\n",
    "\n",
    "    # Find the index of the most dominant color\n",
    "    b, g, r = np.unravel_index(hist.argmax(), hist.shape)\n",
    "\n",
    "    return (r, g, b)\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('images/5725_HASAN_MARAE Optic nerve.png_ right.png')\n",
    "\n",
    "# Select the ROI\n",
    "roi = select_roi(image)\n",
    "\n",
    "# Get the dominant color within the selected area\n",
    "dominant_color = get_dominant_color(image, roi)\n",
    "\n",
    "# Display the dominant color\n",
    "print(\"Dominant color (RGB):\", dominant_color)\n",
    "\n",
    "# Optionally, you can convert the RGB values to the corresponding color name\n",
    "\n",
    "# Show the image with the selected ROI\n",
    "cv2.rectangle(image, (roi[0], roi[1]), (roi[0] + roi[2], roi[1] + roi[3]), (0, 255, 0), 2)\n",
    "cv2.imshow('Image with ROI', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected pixel color (BGR): [ 26 212  15]\n",
      "Selected pixel color (BGR): [ 16 144   0]\n",
      "Selected pixel color (BGR): [ 70 148   9]\n",
      "Selected pixel color (BGR): [ 21 209  11]\n",
      "Selected pixel color (BGR): [ 27 212  11]\n",
      "Selected pixel color (BGR): [59 42  3]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def get_pixel_color(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        pixel = image[y, x]  # Get the BGR values of the clicked pixel\n",
    "        print(\"Selected pixel color (BGR):\", pixel)\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('images/5725_HASAN_MARAE Optic nerve.png_ right.png')\n",
    "\n",
    "# Display the image and set up the mouse callback function\n",
    "cv2.imshow('Select Pixel', image)\n",
    "cv2.setMouseCallback('Select Pixel', get_pixel_color)\n",
    "\n",
    "# Wait for the user to click on the image\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of colors in the image: 8\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def count_colors(image_path, k=8):\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert image to RGB (if not already)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Flatten the image to 1D array\n",
    "    pixels = image_rgb.reshape(-1, 3)\n",
    "    \n",
    "    # Convert to float32 for k-means\n",
    "    pixels = np.float32(pixels)\n",
    "    \n",
    "    # Apply k-means clustering\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Count unique colors\n",
    "    unique_colors = np.unique(centers, axis=0)\n",
    "    num_colors = len(unique_colors)\n",
    "    \n",
    "    return num_colors\n",
    "\n",
    "# Example usage\n",
    "image_path = \"images/5725_HASAN_MARAE Optic nerve.png_ right.png\"\n",
    "num_colors = count_colors(image_path)\n",
    "print(\"Number of colors in the image:\", num_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color: 0 Rate: 0.028653617397669737\n",
      "Color: 1 Rate: 0.020997275259765347\n",
      "Color: 2 Rate: 0.0035774924256288254\n",
      "Color: 3 Rate: 0.04525496146729295\n",
      "Color: 4 Rate: 0.011285304703226987\n",
      "Color: 5 Rate: 0.006429954858781187\n",
      "Color: 6 Rate: 0.7913807214461457\n",
      "Color: 7 Rate: 0.09242067244148926\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def count_colors(image_path, k=8):\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert image to RGB (if not already)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Flatten the image to 1D array\n",
    "    pixels = image_rgb.reshape(-1, 3)\n",
    "    \n",
    "    # Convert to float32 for k-means\n",
    "    pixels = np.float32(pixels)\n",
    "    \n",
    "    # Apply k-means clustering\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Count unique colors and their frequencies\n",
    "    unique_colors, counts = np.unique(labels, return_counts=True)\n",
    "    total_pixels = np.sum(counts)\n",
    "    color_rates = counts / total_pixels\n",
    "    \n",
    "    return unique_colors, color_rates\n",
    "\n",
    "# Example usage\n",
    "image_path = \"images/5725_HASAN_MARAE Optic nerve.png_ right.png\"\n",
    "unique_colors, color_rates = count_colors(image_path)\n",
    "for color, rate in zip(unique_colors, color_rates):\n",
    "    print(\"Color:\", color, \"Rate:\", rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {}\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color: [ 82 245  38] Rate: 0.050214957917970364\n",
      "Color: [ 4 56 75] Rate: 0.7092368235950424\n",
      "Color: [  5  99 131] Rate: 0.14566809769822212\n",
      "Color: [ 22 174 203] Rate: 0.09488012078876519\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import webcolors\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def rgb_to_name(rgb_tuple):\n",
    "    try:\n",
    "        color_name = webcolors.rgb_to_name(rgb_tuple)\n",
    "    except ValueError:\n",
    "        # If the RGB value doesn't match any named color, return None\n",
    "        color_name = None\n",
    "    return color_name\n",
    "\n",
    "def count_colors(image_path, k=4):\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert image to RGB (if not already)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Flatten the image to 1D array\n",
    "    pixels = image_rgb.reshape(-1, 3)\n",
    "    \n",
    "    # Convert to float32 for k-means\n",
    "    pixels = np.float32(pixels)\n",
    "    \n",
    "    # Apply k-means clustering\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Count unique colors and their frequencies\n",
    "    unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "    total_pixels = np.sum(counts)\n",
    "    color_rates = counts / total_pixels\n",
    "    \n",
    "    # Convert cluster centers to uint8 for color representation\n",
    "    centers = np.uint8(centers)\n",
    "    \n",
    "    # Initialize lists to store color information\n",
    "    colors = []\n",
    "    color_names = []\n",
    "    \n",
    "    # Map RGB values to color names\n",
    "    for color in centers:\n",
    "        color_name = rgb_to_name(tuple(color))\n",
    "        colors.append(color)\n",
    "        color_names.append(color_name)\n",
    "    \n",
    "    return colors, color_names, color_rates\n",
    "\n",
    "# Example usage\n",
    "image_path = \"images/5725_HASAN_MARAE Optic nerve.png_ right2.png\"\n",
    "colors, color_names, color_rates = count_colors(image_path)\n",
    "for color, color_name, rate in zip(colors, color_names, color_rates):\n",
    "    data.append([color,rate])\n",
    "    print(\"Color:\", color, \"Rate:\", rate)\n",
    "\n",
    "\n",
    "# colors.append({'image':data})    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 92, 244,  33], dtype=uint8),\n",
       " array([ 22, 121, 158], dtype=uint8),\n",
       " array([ 8, 51, 67], dtype=uint8),\n",
       " array([ 61, 219, 126], dtype=uint8),\n",
       " array([ 37, 169, 205], dtype=uint8),\n",
       " array([211, 216, 221], dtype=uint8),\n",
       " array([ 17,  82, 105], dtype=uint8),\n",
       " array([125, 141, 142], dtype=uint8),\n",
       " {'image': [[array([ 61, 220, 124], dtype=uint8), 0.023749974582647066],\n",
       "   [array([ 92, 245,  31], dtype=uint8), 0.025928241729193356],\n",
       "   [array([ 84, 107, 106], dtype=uint8), 0.012174912055958845],\n",
       "   [array([ 23, 125, 161], dtype=uint8), 0.06898523760141524],\n",
       "   [array([189, 195, 201], dtype=uint8), 0.010680371703369324],\n",
       "   [array([ 37, 171, 206], dtype=uint8), 0.07168201874783953],\n",
       "   [array([ 14,  83, 108], dtype=uint8), 0.09203115150775737],\n",
       "   [array([ 8, 51, 67], dtype=uint8), 0.6947680920718192],\n",
       "   [array([ 92, 244,  33], dtype=uint8), 0.026718721405477947],\n",
       "   [array([ 22, 121, 158], dtype=uint8), 0.06939445698367189],\n",
       "   [array([ 8, 51, 67], dtype=uint8), 0.6910291994550519],\n",
       "   [array([ 61, 219, 126], dtype=uint8), 0.02358222005327477],\n",
       "   [array([ 37, 169, 205], dtype=uint8), 0.07588350718802742],\n",
       "   [array([211, 216, 221], dtype=uint8), 0.006483966733768478],\n",
       "   [array([ 17,  82, 105], dtype=uint8), 0.09676894609487789],\n",
       "   [array([125, 141, 142], dtype=uint8), 0.010138982085849652]]}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Counts: {(19, 165, 207): 58717, (4, 56, 74): 461547, (5, 96, 128): 99033, (90, 247, 19): 25374, (50, 232, 127): 14993}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def identify_colors(image_path, num_clusters=5):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Reshape the image into a 2D array of pixels\n",
    "    pixels = image_rgb.reshape(-1, 3)\n",
    "    \n",
    "    # Convert the pixels to float32 for K-means clustering\n",
    "    pixels = np.float32(pixels)\n",
    "    \n",
    "    # Define criteria for K-means\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    \n",
    "    # Apply K-means clustering\n",
    "    _, labels, centers = cv2.kmeans(pixels, num_clusters, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Convert the centers to uint8\n",
    "    centers = np.uint8(centers)\n",
    "    \n",
    "    # Initialize a dictionary to store the counts of each color\n",
    "    color_counts = {}\n",
    "    \n",
    "    # Loop through each pixel and count the occurrences of each color cluster\n",
    "    for label in np.unique(labels):\n",
    "        color = tuple(centers[label])\n",
    "        count = np.sum(labels == label)\n",
    "        color_counts[color] = count\n",
    "    \n",
    "    return color_counts\n",
    "\n",
    "# Example usage\n",
    "image_path = \"images/5725_HASAN_MARAE Optic nerve.png_ right2.png\"\n",
    "color_counts = identify_colors(image_path)\n",
    "print(\"Color Counts:\", color_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Counts: {(36, 165, 193): 43758, (183, 190, 196): 4633, (8, 52, 68): 284408, (84, 237, 58): 16136, (22, 98, 126): 44497}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def identify_colors(image_path, num_clusters=5):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Reshape the image into a 2D array of pixels\n",
    "    pixels = image_rgb.reshape(-1, 3)\n",
    "    \n",
    "    # Convert the pixels to float32 for K-means clustering\n",
    "    pixels = np.float32(pixels)\n",
    "    \n",
    "    # Define criteria for K-means\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    \n",
    "    # Apply K-means clustering\n",
    "    _, labels, centers = cv2.kmeans(pixels, num_clusters, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Convert the centers to uint8\n",
    "    centers = np.uint8(centers)\n",
    "    \n",
    "    # Initialize a dictionary to store the counts of each color\n",
    "    color_counts = {}\n",
    "    \n",
    "    # Loop through each pixel and count the occurrences of each color cluster\n",
    "    for label in np.unique(labels):\n",
    "        color = tuple(centers[label])\n",
    "        count = np.sum(labels == label)\n",
    "        color_counts[color] = count\n",
    "    \n",
    "    # Visualize the image with color clusters\n",
    "    cluster_labels = np.uint8(labels.reshape(image_rgb.shape[:2]))\n",
    "    clustered_image = centers[cluster_labels]\n",
    "    \n",
    "    return color_counts, clustered_image\n",
    "\n",
    "# Example usage\n",
    "image_path = \"images/5725_HASAN_MARAE Optic nerve.png_ left.png\"\n",
    "color_counts, clustered_image = identify_colors(image_path)\n",
    "\n",
    "# Show the original and clustered images\n",
    "cv2.imshow(\"Original Image\", cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
    "cv2.imshow(\"Clustered Image\", cv2.cvtColor(clustered_image, cv2.COLOR_RGB2BGR))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Color Counts:\", color_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Color Counts: {(33, 159, 199): 9140, (17, 99, 129): 8271, (102, 245, 31): 2195, (9, 55, 72): 18774, (62, 213, 117): 1620}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def identify_colors(image_path, num_clusters=5, roi=None):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Convert the image from BGR to RGB\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Define the ROI if provided\n",
    "    if roi is not None:\n",
    "        x, y, w, h = roi\n",
    "        image_rgb = image_rgb[y:y+h, x:x+w]\n",
    "    \n",
    "    # Reshape the image into a 2D array of pixels\n",
    "    pixels = image_rgb.reshape(-1, 3)\n",
    "    \n",
    "    # Convert the pixels to float32 for K-means clustering\n",
    "    pixels = np.float32(pixels)\n",
    "    \n",
    "    # Define criteria for K-means\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
    "    \n",
    "    # Apply K-means clustering\n",
    "    _, labels, centers = cv2.kmeans(pixels, num_clusters, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n",
    "    \n",
    "    # Convert the centers to uint8\n",
    "    centers = np.uint8(centers)\n",
    "    \n",
    "    # Initialize a dictionary to store the counts of each color\n",
    "    color_counts = {}\n",
    "    \n",
    "    # Loop through each pixel and count the occurrences of each color cluster\n",
    "    for label in np.unique(labels):\n",
    "        color = tuple(centers[label])\n",
    "        count = np.sum(labels == label)\n",
    "        color_counts[color] = count\n",
    "    \n",
    "    # Visualize the image with color clusters\n",
    "    cluster_labels = np.uint8(labels.reshape(image_rgb.shape[:2]))\n",
    "    clustered_image = centers[cluster_labels]\n",
    "    \n",
    "    return color_counts, clustered_image\n",
    "\n",
    "# Example usage\n",
    "image_path = \"images/5725_HASAN_MARAE Optic nerve.png_ left.png\"\n",
    "roi = (100, 100, 200, 200)  # Define the ROI as (x, y, width, height)\n",
    "color_counts, clustered_image = identify_colors(image_path, roi=roi)\n",
    "\n",
    "# Show the original and clustered images\n",
    "cv2.imshow(\"Original Image\", cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB))\n",
    "cv2.imshow(\"Clustered Image\", cv2.cvtColor(clustered_image, cv2.COLOR_RGB2BGR))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Color Counts:\", color_counts)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
