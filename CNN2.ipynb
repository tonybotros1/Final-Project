{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout # type: ignore\n",
    "from keras.optimizers import Adam\n",
    "import cv2 as cv\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "split_df = pd.read_csv('split_df.csv', encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table 1</th>\n",
       "      <th>Spectacles</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Name</th>\n",
       "      <th>id</th>\n",
       "      <th>Eye</th>\n",
       "      <th>VA</th>\n",
       "      <th>CDR</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>IOP</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>زرق أيمن تم معالجته جراحيا</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>شاهين ميرو</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Data/SHAHEN_MERO Optic nerve.png_ left.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>زرق أيمن تم معالجته جراحيا</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>شاهين ميرو</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Data/SHAHEN_MERO Optic nerve.png_ left.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>زرق متقدم</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>أيمن سمارة</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Data/SHAHEN_MERO Optic nerve.png_ right.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>زرق متقدم</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>أيمن سمارة</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Data/SHAHEN_MERO Optic nerve.png_ right.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>لا يوجد زرق</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>رندة ناصر</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>زرق أيسر تم معالجته جراحيا</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>زريفة المحمد</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data/BASEL_BASH Optic nerve.png_ left.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>مريض زرقي ثانوي بعد استخراج ساد لا يوجد اصابة ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>هيثم قزاز</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Data/BASEL_BASH Optic nerve.png_ right.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>مريض زرقي ثانوي بعد استخراج ساد لا يوجد اصابة ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>هيثم قزاز</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Data/BASEL_BASH Optic nerve.png_ right.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>لا يوجد زرق</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>حمود غشام</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Data/NEZAR_HELOU Optic nerve.png_ left.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>لا يوجد زرق</td>\n",
       "      <td>1.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>حمود غشام</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Data/NEZAR_HELOU Optic nerve.png_ left.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Table 1  Spectacles  Age  \\\n",
       "0                          زرق أيمن تم معالجته جراحيا         0.0   64   \n",
       "1                          زرق أيمن تم معالجته جراحيا         0.0   64   \n",
       "2                                           زرق متقدم         1.0   62   \n",
       "3                                           زرق متقدم         1.0   62   \n",
       "4                                         لا يوجد زرق         0.0   48   \n",
       "..                                                ...         ...  ...   \n",
       "85                         زرق أيسر تم معالجته جراحيا         1.0   55   \n",
       "86  مريض زرقي ثانوي بعد استخراج ساد لا يوجد اصابة ...         0.0   71   \n",
       "87  مريض زرقي ثانوي بعد استخراج ساد لا يوجد اصابة ...         0.0   71   \n",
       "88                                        لا يوجد زرق         1.0   65   \n",
       "89                                        لا يوجد زرق         1.0   65   \n",
       "\n",
       "    Gender          Name    id  Eye   VA  CDR  Diagnosis   IOP  \\\n",
       "0        0    شاهين ميرو   1.0    0  0.6  0.5          0  14.0   \n",
       "1        0    شاهين ميرو   1.0    1  0.7  0.9          1  23.0   \n",
       "2        0    أيمن سمارة   2.0    0  NaN  NaN          1  25.0   \n",
       "3        0    أيمن سمارة   2.0    1  9.0  0.8          1  40.0   \n",
       "4        1     رندة ناصر   3.0    0  1.0  0.5          0  15.0   \n",
       "..     ...           ...   ...  ...  ...  ...        ...   ...   \n",
       "85       1  زريفة المحمد  43.0    1  NaN  NaN          0   NaN   \n",
       "86       0     هيثم قزاز  44.0    0  0.3  0.5          1  15.0   \n",
       "87       0     هيثم قزاز  44.0    1  0.6  0.7          1  16.0   \n",
       "88       0     حمود غشام  45.0    0  0.5  0.3          0  15.0   \n",
       "89       0     حمود غشام  45.0    1  0.2  0.3          0  12.0   \n",
       "\n",
       "                                          Image  \n",
       "0    Data/SHAHEN_MERO Optic nerve.png_ left.png  \n",
       "1    Data/SHAHEN_MERO Optic nerve.png_ left.png  \n",
       "2   Data/SHAHEN_MERO Optic nerve.png_ right.png  \n",
       "3   Data/SHAHEN_MERO Optic nerve.png_ right.png  \n",
       "4                                           NaN  \n",
       "..                                          ...  \n",
       "85    Data/BASEL_BASH Optic nerve.png_ left.png  \n",
       "86   Data/BASEL_BASH Optic nerve.png_ right.png  \n",
       "87   Data/BASEL_BASH Optic nerve.png_ right.png  \n",
       "88   Data/NEZAR_HELOU Optic nerve.png_ left.png  \n",
       "89   Data/NEZAR_HELOU Optic nerve.png_ left.png  \n",
       "\n",
       "[90 rows x 12 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = split_df.drop(['Table 1', 'Gender', 'id', 'Age', 'Spectacles'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df = split_df.drop(['Name','Eye'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VA</th>\n",
       "      <th>CDR</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>IOP</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Data/SHAHEN_MERO Optic nerve.png_ left.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Data/SHAHEN_MERO Optic nerve.png_ left.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Data/SHAHEN_MERO Optic nerve.png_ right.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Data/AYMAN_SAMARA_20240121_124719_Disc_3D_R_SI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Data/AYMAN_SAMARA_20240121_124719_Disc_3D_R_SI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Data/BASEL_BASH Optic nerve.png_ left.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Data/BASEL_BASH Optic nerve.png_ right.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Data/BASEL_BASH Optic nerve.png_ right.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Data/NEZAR_HELOU Optic nerve.png_ left.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Data/NEZAR_HELOU Optic nerve.png_ left.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     VA  CDR  Diagnosis   IOP  \\\n",
       "0   0.6  0.5          0  14.0   \n",
       "1   0.7  0.9          1  23.0   \n",
       "3   9.0  0.8          1  40.0   \n",
       "6   0.2  0.7          1  10.0   \n",
       "7   0.1  0.7          1  14.0   \n",
       "..  ...  ...        ...   ...   \n",
       "84  0.2  0.8          1  10.0   \n",
       "86  0.3  0.5          1  15.0   \n",
       "87  0.6  0.7          1  16.0   \n",
       "88  0.5  0.3          0  15.0   \n",
       "89  0.2  0.3          0  12.0   \n",
       "\n",
       "                                                Image  \n",
       "0          Data/SHAHEN_MERO Optic nerve.png_ left.png  \n",
       "1          Data/SHAHEN_MERO Optic nerve.png_ left.png  \n",
       "3         Data/SHAHEN_MERO Optic nerve.png_ right.png  \n",
       "6   Data/AYMAN_SAMARA_20240121_124719_Disc_3D_R_SI...  \n",
       "7   Data/AYMAN_SAMARA_20240121_124719_Disc_3D_R_SI...  \n",
       "..                                                ...  \n",
       "84          Data/BASEL_BASH Optic nerve.png_ left.png  \n",
       "86         Data/BASEL_BASH Optic nerve.png_ right.png  \n",
       "87         Data/BASEL_BASH Optic nerve.png_ right.png  \n",
       "88         Data/NEZAR_HELOU Optic nerve.png_ left.png  \n",
       "89         Data/NEZAR_HELOU Optic nerve.png_ left.png  \n",
       "\n",
       "[66 rows x 5 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split_df['Image'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data/SHAHEN_MERO Optic nerve.png_ left.png'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_df['Image'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# # Preprocess image function\n",
    "# def preprocess_image(image_path, target_size=(224, 224)):\n",
    "#     # Read the image\n",
    "#     image = cv2.imread(image_path)\n",
    "    \n",
    "#     # Resize the image\n",
    "#     image = cv2.resize(image, target_size)\n",
    "    \n",
    "#     # Convert the image to float32\n",
    "#     image = image.astype(np.float32)\n",
    "    \n",
    "#     # Normalize pixel values to [0, 1]\n",
    "#     image /= 255.0\n",
    "    \n",
    "#     return image\n",
    "\n",
    "# Concatenation model\n",
    "def create_concat_model(image_shape, num_numerical_features, num_classes):\n",
    "    # Define input layers for images and numerical features\n",
    "    image_input = Input(shape=image_shape)\n",
    "    numerical_input = Input(shape=(num_numerical_features,))\n",
    "    \n",
    "    # Image processing layers\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    flatten_img = Flatten()(pool2)\n",
    "    \n",
    "    # Dense layers for numerical features\n",
    "    dense1 = Dense(64, activation='relu')(numerical_input)\n",
    "    \n",
    "    # Concatenate image and feature layers\n",
    "    concatenated = Concatenate()([flatten_img, dense1])\n",
    "    \n",
    "    # Additional layers for further processing or output\n",
    "    dense2 = Dense(128, activation='relu')(concatenated)\n",
    "    output = Dense(num_classes, activation='sigmoid')(dense2)\n",
    "    \n",
    "    # Define the model\n",
    "    model = tf.keras.Model(inputs=[image_input, numerical_input], outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Data augmentation\n",
    "data_generator = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "augmented_images = []\n",
    "\n",
    "for index,row in split_df.iterrows():\n",
    "    # Load an image and preprocess it\n",
    "    path = row['Image']\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "    image = cv2.resize(image, (224, 224))  # Resize the image to the desired size\n",
    "    image = image.astype(np.float32) / 255.0  # Normalize pixel values to [0, 1]\n",
    "    augmented_images.append(image)\n",
    "\n",
    "\n",
    "    # # Apply data augmentation\n",
    "    # for _ in range(5):  # Generate 5 augmented images\n",
    "    #     augmented_image = data_generator.random_transform(image)\n",
    "    #     augmented_images.append(augmented_image)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = split_df.drop(['Diagnosis','Image'],axis=1)\n",
    "numerical_features = np.array(numerical_features)\n",
    "labels = np.array(split_df['Diagnosis'])  # NumPy array of shape (num_samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 3)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "image_shape = augmented_images[0].shape \n",
    "num_numerical_features = 3 \n",
    "num_classes = 1  \n",
    "concat_model = create_concat_model(image_shape, num_numerical_features, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "concat_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 222, 222, 32)         896       ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 111, 111, 32)         0         ['conv2d[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)         18496     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)           0         ['conv2d_1[0][0]']            \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 3)]                  0         []                            \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 186624)               0         ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 64)                   256       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 186688)               0         ['flatten[0][0]',             \n",
      "                                                                     'dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 128)                  2389619   ['concatenate[0][0]']         \n",
      "                                                          2                                       \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 1)                    129       ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 23915969 (91.23 MB)\n",
      "Trainable params: 23915969 (91.23 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "concat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.1, random_state=44, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image_train, X_image_test, X_num_features_train, X_num_features_test, y_labels_train, y_labels_test = train_test_split(augmented_images, numerical_features, labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "7\n",
      "59\n",
      "7\n",
      "59\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(X_image_train))\n",
    "print(len(X_image_test))\n",
    "print(len(X_num_features_train))\n",
    "print(len(X_num_features_test))\n",
    "print(len(y_labels_train))\n",
    "print(len(y_labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "14\n",
      "52\n",
      "14\n",
      "52\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "X_image_train, X_image_test, X_num_features_train, X_num_features_test, y_labels_train, y_labels_test = \\\n",
    "    train_test_split(augmented_images, numerical_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(len(X_image_train))\n",
    "print(len(X_image_test))\n",
    "print(len(X_num_features_train))\n",
    "print(len(X_num_features_test))\n",
    "print(len(y_labels_train))\n",
    "print(len(y_labels_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labels_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[X_image_train, X_num_features_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52, 224, 224, 3) (52, 3) (52,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # تأكد من استيراد مكتبة numpy\n",
    "\n",
    "# تحويل القوائم إلى مصفوفات numpy\n",
    "X_image_train_np = np.array(X_image_train)\n",
    "X_num_features_train_np = np.array(X_num_features_train)\n",
    "y_labels_train_np = np.array(y_labels_train)\n",
    "\n",
    "# طباعة الأبعاد\n",
    "print(X_image_train_np.shape, X_num_features_train_np.shape, y_labels_train_np.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 1s/step - loss: 4.9263 - accuracy: 0.5769 - val_loss: 1.2020 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 2s 855ms/step - loss: 1.6404 - accuracy: 0.7308 - val_loss: 3.6957 - val_accuracy: 0.3571\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 2s 856ms/step - loss: 1.9167 - accuracy: 0.5192 - val_loss: 0.7059 - val_accuracy: 0.6429\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 2s 874ms/step - loss: 0.9048 - accuracy: 0.5769 - val_loss: 0.8147 - val_accuracy: 0.6429\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 2s 942ms/step - loss: 0.8410 - accuracy: 0.5769 - val_loss: 0.6055 - val_accuracy: 0.5714\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 2s 844ms/step - loss: 0.4172 - accuracy: 0.8269 - val_loss: 1.1145 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 2s 848ms/step - loss: 0.4184 - accuracy: 0.8077 - val_loss: 1.0147 - val_accuracy: 0.5714\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 2s 793ms/step - loss: 0.3020 - accuracy: 0.8654 - val_loss: 0.9224 - val_accuracy: 0.6429\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 2s 755ms/step - loss: 0.2882 - accuracy: 0.8846 - val_loss: 1.0862 - val_accuracy: 0.5714\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 2s 747ms/step - loss: 0.2087 - accuracy: 0.9038 - val_loss: 1.3892 - val_accuracy: 0.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e21d639590>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_model.fit(x=[np.array(X_image_train), X_num_features_train], y=y_labels_train, validation_data=([np.array(X_image_test), X_num_features_test], y_labels_test),\n",
    "                  batch_size=32, epochs=10, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 2s 834ms/step - loss: 0.2082 - accuracy: 0.8846 - val_loss: 1.2372 - val_accuracy: 0.5714\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 2s 800ms/step - loss: 0.1665 - accuracy: 0.9038 - val_loss: 1.1916 - val_accuracy: 0.5714\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 2s 813ms/step - loss: 0.1573 - accuracy: 0.8846 - val_loss: 1.4698 - val_accuracy: 0.5714\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 2s 832ms/step - loss: 0.1683 - accuracy: 0.9615 - val_loss: 1.7097 - val_accuracy: 0.5714\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 2s 838ms/step - loss: 0.1258 - accuracy: 0.9615 - val_loss: 1.6987 - val_accuracy: 0.5714\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 2s 749ms/step - loss: 0.1627 - accuracy: 0.9423 - val_loss: 1.8010 - val_accuracy: 0.5714\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 2s 735ms/step - loss: 0.1570 - accuracy: 0.9038 - val_loss: 2.0660 - val_accuracy: 0.5714\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 2s 795ms/step - loss: 0.1321 - accuracy: 0.9231 - val_loss: 2.3285 - val_accuracy: 0.5714\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 2s 840ms/step - loss: 0.1407 - accuracy: 0.9038 - val_loss: 2.1493 - val_accuracy: 0.5714\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 2s 779ms/step - loss: 0.1368 - accuracy: 0.9038 - val_loss: 1.9244 - val_accuracy: 0.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1e21d811590>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_model.fit(x=[np.array(X_image_train), X_num_features_train], y=y_labels_train, validation_data=([np.array(X_image_test), X_num_features_test], y_labels_test),\n",
    "                  batch_size=32, epochs=10, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
